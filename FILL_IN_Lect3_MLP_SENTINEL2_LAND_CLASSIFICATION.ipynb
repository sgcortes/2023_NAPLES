{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgcortes/2023_NAPLES/blob/main/FILL_IN_Lect3_MLP_SENTINEL2_LAND_CLASSIFICATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dIopgxaiefH"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "  <tr>\n",
        "    <td><img src=\"https://unioviedo-my.sharepoint.com/:i:/g/personal/sgcortes_uniovi_es/Ebr0ybKDTBNKtoJyzmTBuRYBXY7nE-cCYaH-WDIVJxEVWA?&download=1\" width=\"211\" height=\"69\" alt=\"Uniovi & EP Mieres logos\" title=\"Uniovi & EP Mieres logos\" /></td>\n",
        "    <td><font color=brown>Deep Learning<br></font>\n",
        "    <font color=green>Universidad de Oviedo. <br>ML & DL Naples 2023</font> <br><br>sgcortes@uniovi.es</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMmtcFoNjFyw",
        "outputId": "9d8f94f9-4e5f-4b6a-9c05-aebd4c1b130a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-23 00:30:53--  https://unioviedo-my.sharepoint.com/:u:/g/personal/sgcortes_uniovi_es/ESV-U5iHa_FIu2WVnU_Ysu0BLFb1BX1hzvzTFbivXLj1ZA?e=GOfJP9&download=1\n",
            "Resolving unioviedo-my.sharepoint.com (unioviedo-my.sharepoint.com)... 13.107.136.8, 13.107.138.8, 2620:1ec:8f8::8, ...\n",
            "Connecting to unioviedo-my.sharepoint.com (unioviedo-my.sharepoint.com)|13.107.136.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/sgcortes_uniovi_es/Documents/2020_VISION/EuroSAT.zip?ga=1 [following]\n",
            "--2023-05-23 00:30:55--  https://unioviedo-my.sharepoint.com/personal/sgcortes_uniovi_es/Documents/2020_VISION/EuroSAT.zip?ga=1\n",
            "Reusing existing connection to unioviedo-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94280567 (90M) [application/x-zip-compressed]\n",
            "Saving to: ‘EuroSAT.zip’\n",
            "\n",
            "EuroSAT.zip         100%[===================>]  89.91M  23.1MB/s    in 5.9s    \n",
            "\n",
            "2023-05-23 00:31:01 (15.3 MB/s) - ‘EuroSAT.zip’ saved [94280567/94280567]\n",
            "\n",
            "replace 2750/River/River_479.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# THIS CELL MUST BE EXECUTED ONLY ONCE. IF NOT ERRORS WILL APPEAR BECAUSE OF DUPLICATION OF THE DATASET IN THE SESSION.\n",
        "#!wget http://madm.dfki.de/files/sentinel/EuroSAT.zip\n",
        "#!pip install tensorflow==2.2.0\n",
        "# Las dos líneas anteriores no serán necesarias en general ya que TensorFlow está instalado por defecto en Google Colab y el enlace siguiente a uniovi shaorepoint funciona para descargar los datos. \n",
        "!wget -O EuroSAT.zip 'https://unioviedo-my.sharepoint.com/:u:/g/personal/sgcortes_uniovi_es/ESV-U5iHa_FIu2WVnU_Ysu0BLFb1BX1hzvzTFbivXLj1ZA?e=GOfJP9&download=1'\n",
        "!unzip -qq EuroSAT.zip\n",
        "%cd 2750\n",
        "\n",
        "#NOTE: RUN THIS CELL ONLY ONCE. After first execution the dataset should be locally in the Google sesion content folder.\n",
        "# AFTER FIRST EXECUTION SIMPLY COMMENT THE 3 COMMAND TO AVOID NEW EXECCUTIONS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL1kHDj9jFeQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbsILNiziefM"
      },
      "source": [
        "## Scene Multiclass Classification Example with MLP (Multilayer Perceptron)\n",
        "In this example the dataset from the file EUROSAT.zip will be clssified using a MLP. Images are RGB 64x64 pixels size. These tiles are stored in folder which names are the real class name they belong to.  \n",
        "\n",
        "The original dataset can be dowloaded also from: http://madm.dfki.de/downloads\n",
        "There are about 27.000 subimáges from Sentinel 2 imagery in this dataset.\n",
        "\n",
        "**Please try to complete the empty code to finish with all the steps of the classification.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv6rTc8jiefN"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.metrics import f1_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "ruta_datos = '/content/2750/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdu0lUYdiefP"
      },
      "source": [
        "The sub-images are organised in folders whose names are the names of the data classes, which are 10 types of land cover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isO_BUAtiefQ"
      },
      "outputs": [],
      "source": [
        "clases = os.listdir(ruta_datos)\n",
        "print(clases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p3aca7-iefS"
      },
      "source": [
        "## Loading data.\n",
        "We will create a dictionary of classes with the equivalence of the class number and its name, two matrices, one of input data with all the image matrices and another one (a vector actually) with the digit indicating the class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbS18zMciefT"
      },
      "outputs": [],
      "source": [
        "dic_clases = {}\n",
        "datos_entrada = []\n",
        "datos_salida = []\n",
        "i = 0\n",
        "\n",
        "for i, clase in enumerate(clases):\n",
        "    if os.path.isdir(ruta_datos+clase):\n",
        "        for file in os.listdir(ruta_datos+clase):\n",
        "            im = Image.open(os.path.join(ruta_datos, clase,file))\n",
        "            im_array = np.array(im)\n",
        "            datos_entrada.append(im_array)\n",
        "            datos_salida.append(i)\n",
        "        dic_clases[i] = clase\n",
        "        \n",
        "        \n",
        "datos_entrada = np.array(datos_entrada)\n",
        "datos_salida = np.array(datos_salida)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAXfmAzbiefT"
      },
      "outputs": [],
      "source": [
        "print('Input data shape: ', datos_entrada.shape)\n",
        "print('Data Type: ', datos_entrada.dtype)\n",
        "print('Class label index: (First 5 elements) \\n',datos_salida[0:5])\n",
        "print(dic_clases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eEa9e7siefV"
      },
      "source": [
        "Display of one land cover image from of each class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RgHhRtmiefX"
      },
      "outputs": [],
      "source": [
        "print(datos_salida.shape)\n",
        "ind_ejemplos = [np.where(datos_salida == i)[0][0] for i in range(10)]\n",
        "print(ind_ejemplos)\n",
        "fig, axs = plt.subplots(2,5, figsize=(15,6))\n",
        "axs = axs.ravel()\n",
        "for i,ax in enumerate(axs):\n",
        "    axs[i].imshow(datos_entrada[ind_ejemplos[i]])\n",
        "    axs[i].set_title(clases[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igzyYtZgiefX"
      },
      "source": [
        "## Training and validation spliting\n",
        "We split the data into a training set (80%) and the rest of the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QawJM7GiefY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image data normalization"
      ],
      "metadata": {
        "id": "uZOpRTP99KQd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLzgee3KiefY"
      },
      "outputs": [],
      "source": [
        "# Imágery normalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data resizing\n",
        "Tensor size for MLP must be one row per sample and as many columnas as pixel there exist in the subimage."
      ],
      "metadata": {
        "id": "0IV082Zx9kxL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU6thRj7iefZ"
      },
      "outputs": [],
      "source": [
        "# Check dataset size and reshape\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzkehW06iefZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class label codification with One-hot encoding"
      ],
      "metadata": {
        "id": "_S2A1JwE958Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l153kJE0iefZ"
      },
      "outputs": [],
      "source": [
        "# one-hot encoding for class vectors (training and test datasets) :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt15Hww6iefa"
      },
      "source": [
        "### Model design"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQFTqS-Giefb"
      },
      "outputs": [],
      "source": [
        "mlp1 = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mlp.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IT8aFpZiefb"
      },
      "source": [
        "The output layer has to be softmax as it is a \"multi-class\" classification problem and must have 10 neurons as there are 10 classes to classify. The input size must also be 12288 which is the product of 64 x 64 x 3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYWO_5xAiefc"
      },
      "source": [
        "### Model compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K41LgWwgiefc"
      },
      "outputs": [],
      "source": [
        "mlp1.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "tPGDW-4c-jSM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v7CnfIGiefc"
      },
      "outputs": [],
      "source": [
        "hist = mlp1.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv0SwFC_iefc"
      },
      "source": [
        "### Model Validation:\n",
        "Loss and accuracy graphics through the epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_E5Ap3ziefd"
      },
      "outputs": [],
      "source": [
        "plt.plot(hist.history['loss'], label='Training')\n",
        "plt.plot(hist.history['val_loss'], label='Validation')\n",
        "plt.xlabel('Épochs')\n",
        "plt.ylabel('Loss Function')\n",
        "plt.legend()\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJZEqVpdiefd"
      },
      "source": [
        "### Model evaluation: Evolution of accuracy over epochs for the training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngXche5Wiefd"
      },
      "outputs": [],
      "source": [
        "plt.plot(hist.history['accuracy'], label='Training')\n",
        "plt.plot(hist.history['val_accuracy'], label='Validation')\n",
        "plt.xlabel('Épochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdtOQMyhiefd"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVmncV5riefe"
      },
      "outputs": [],
      "source": [
        "y_prob_train = mlp1.predict(x_train)\n",
        "y_prob_test = mlp1.predict(x_test)\n",
        "\n",
        "y_pred_train = np.argmax(y_prob_train, axis=1)\n",
        "y_pred_test = np.argmax(y_prob_test, axis=1)\n",
        "print(y_pred_train[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51Lk7tA3iefe"
      },
      "source": [
        "### Metrics: precision, recall, accuracy and F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYwfWx2wiefe"
      },
      "outputs": [],
      "source": [
        "acc_train = accuracy_score(clases_train, y_pred_train)\n",
        "acc_test = accuracy_score(clases_test, y_pred_test)\n",
        "\n",
        "prec_train = precision_score(clases_train, y_pred_train, average='macro')\n",
        "prec_test = precision_score(clases_test, y_pred_test, average='macro')\n",
        "\n",
        "rec_train = recall_score(clases_train, y_pred_train, average='macro')\n",
        "rec_test = recall_score(clases_test, y_pred_test, average='macro')\n",
        "\n",
        "f1_train = f1_score(clases_train, y_pred_train, average='macro')\n",
        "f1_test = f1_score(clases_test, y_pred_test, average='macro')\n",
        "\n",
        "print('Training accuracy: ', format(100*acc_train, '.2f'),'%')\n",
        "print('Validatión accuracy', format(100*acc_test, '.2f'),'\\n')\n",
        "\n",
        "\n",
        "print('Training precision: ', format(100*prec_train, '.2f'),'%')\n",
        "print('Validation precision', format(100*prec_test, '.2f'),'\\n')\n",
        "\n",
        "print('Training recall: ', format(100*rec_train, '.2f'),'%')\n",
        "print('Validation recall', format(100*rec_test, '.2f'),'\\n')\n",
        "\n",
        "print('Training F1 ', format(f1_train, '.3f'))\n",
        "print('Validation F1 ', format(f1_test, '.3f'),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44-Wdi2diefe"
      },
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn4fBi9Uieff"
      },
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "cm = confusion_matrix()\n",
        "\n",
        "# Gráficas matriz confusion\n",
        "fig,ax = plt.subplots(figsize=(10,10))\n",
        "im = ax.imshow(cm, interpolation='nearest')\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "# Añade títulos y etiquetas al gráfico\n",
        "ax.set(xticks=np.arange(cm.shape[1]),\n",
        "       yticks=np.arange(cm.shape[0]),\n",
        "       xticklabels=clases, yticklabels=clases,\n",
        "       title='Confusion Matrix',\n",
        "       ylabel='Predicted Classes',\n",
        "       xlabel='True Classes')\n",
        "\n",
        "# Rota los nombres de las etiquetas en el eje x\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "        rotation_mode=\"anchor\")\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j,i, cm[i,j],\n",
        "               ha=\"center\", va=\"center\",\n",
        "               color=\"white\" if cm[i,j] <350 else \"black\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}